{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "We've been on the user (or query) side of APIs before, now we're going to be on the server side.\n",
    "\n",
    "The simplest and most popular python framework for serving an API is [Flask](https://flask.palletsprojects.com/en/1.1.x/quickstart/)\n",
    "\n",
    "We will be using the `01_flask_example.py` file as an example of a simple deployment of a model trained on the Titanic data set.\n",
    "\n",
    "You can start it by running it from the command line `python 01_flask_example.py`\n",
    "\n",
    "Then go to your browser to `http://0.0.0.0:5000/` and you'll see `Hello World` being printed. Similarly if we do a `GET` request in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "df = df.drop(['deck','parch','sibsp','class','who','embark_town','alive'],axis=1)\n",
    "df[['adult_male','alone']] = df[['adult_male','alone']].astype(int)\n",
    "df['pclass'] = df['pclass'].astype(object)\n",
    "df = pd.get_dummies(df,drop_first=True)\n",
    "df = df.dropna()\n",
    "df[['age','fare']] = df[['age','fare']].apply(lambda x: x/x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('survived',axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train,y_train)\n",
    "preds = log_model.predict(X_test)\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our model \n",
    "file_name = 'titanic_model'\n",
    "\n",
    "with open(file_name, 'wb') as file:\n",
    "    pickle.dump(log_model,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each positional value we feed our model aligns with each feature column \n",
    "\n",
    "df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results might differ \n",
    "\n",
    "example1 = [22,125,0,0,0,0,0,0,1] # -> 1\n",
    "example2 = [32,15,1,1,0,1,1,0,0] # -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = np.array(example1)\n",
    "data_arr = np.array(example2)\n",
    "\n",
    "data_arr = data_arr.reshape(1,-1)\n",
    "\n",
    "log_model.predict(data_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
